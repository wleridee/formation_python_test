---
sidebar_label: Concurrence : Processus (multiprocessing)
sidebar_position: 43
---

# Chapitre 43 : Concurrence : Processus (multiprocessing)

Diff√©rence threads/processus, Cr√©ation de processus, Communication inter-processus, Pool de processus

Dans le chapitre pr√©c√©dent, nous avons vu que les **Threads** sont excellents pour g√©rer les attentes (Entr√©es/Sorties), mais incapables d'utiliser plusieurs c≈ìurs de votre processeur simultan√©ment √† cause du GIL (Global Interpreter Lock).

Pour faire du calcul intensif (traitement d'image, machine learning, analyse de donn√©es) et utiliser toute la puissance de votre machine, il faut sortir de l'interpr√©teur Python unique. Le module `multiprocessing` permet de cr√©er des **Processus** ind√©pendants, chacun ayant son propre interpr√©teur Python, sa propre m√©moire et... son propre GIL !

---

## 1. Processus vs Threads : Le Grand Duel {#processus-vs-threads}

### 1. Quoi
*   **Processus** : Une instance ind√©pendante d'un programme. Il poss√®de son propre espace m√©moire isol√©. Cr√©er un processus est "lourd" pour le syst√®me.
*   **Thread** : Une unit√© d'ex√©cution *au sein* d'un processus. Il partage la m√©moire du processus parent. Cr√©er un thread est "l√©ger".

### 2. Pourquoi
En Python, `multiprocessing` est la seule fa√ßon native de contourner le GIL pour parall√©liser des t√¢ches **CPU-bound** (qui consomment du processeur).

### 3. Comment

#### D. Tableau comparatif

| Caract√©ristique | Threads (`threading`) | Processus (`multiprocessing`) |
| :--- | :--- | :--- |
| **M√©moire** | Partag√©e (Danger Race Conditions) | Isol√©e (S√©curis√© par d√©faut) |
| **C≈ìurs CPU** | 1 seul (√† cause du GIL) | Tous les c≈ìurs disponibles |
| **Co√ªt de d√©marrage** | Faible | √âlev√© (doit copier l'environnement) |
| **Communication** | Facile (variables partag√©es) | Complexe (Queue, Pipe, IPC) |
| **Cas d'usage** | I/O (R√©seau, Disque) | CPU (Calculs math√©matiques) |

---

## 2. Cr√©ation de Processus {#creation-de-processus}

### 1. Quoi
L'API de `multiprocessing` imite celle de `threading`. On cr√©e un objet `Process` au lieu de `Thread`.

### 2. Pourquoi
Pour lancer une t√¢che lourde sur un c≈ìur s√©par√© sans bloquer le processus principal.

### 3. Comment

#### A. Syntaxe de base

```python
import multiprocessing
import time

def cpu_heavy_task(name):
    print(f"üî• Processus {name} d√©marre sur le CPU")
    # Simulation de calcul intensif
    result = sum(i*i for i in range(10**7))
    print(f"‚úÖ Processus {name} termin√©. R√©sultat: {result}")

if __name__ == "__main__":
    # ‚ö†Ô∏è IMPORTANT : En multiprocessing, le code de lancement 
    # DOIT √™tre prot√©g√© par if __name__ == "__main__" sous Windows/macOS.
    
    p1 = multiprocessing.Process(target=cpu_heavy_task, args=("A",))
    p2 = multiprocessing.Process(target=cpu_heavy_task, args=("B",))

    p1.start()
    p2.start()

    p1.join()
    p2.join()
    print("üèÅ Tout est fini")
```

### 4. Zone de Danger
‚ùå **Oublier le bloc `if __name__ == "__main__"`** : Sur Windows et macOS, Python doit r√©importer le script principal pour lancer le nouveau processus. Si le code de cr√©ation n'est pas prot√©g√©, vous cr√©ez une boucle infinie de cr√©ation de processus ("Fork bomb") qui peut planter votre machine.

---

## 3. Pool de Processus : La Puissance Industrielle {#pool-de-processus}

### 1. Quoi
L'objet `Pool` permet de g√©rer un ensemble fixe de processus ouvriers (workers) et de leur distribuer des t√¢ches automatiquement.

### 2. Pourquoi
Pour ne pas saturer le syst√®me. Si vous avez 4 c≈ìurs et 100 t√¢ches, lancer 100 processus tuerait la machine. Un Pool de 4 processus traitera les 100 t√¢ches par lots, de mani√®re optimale.

### 3. Comment

#### A. Utilisation de `Pool` avec `map`

```python
from multiprocessing import Pool
import os

def square(x):
    # Affiche l'ID du processus syst√®me (PID) pour prouver le parall√©lisme
    return f"Input: {x}, Carr√©: {x*x}, PID: {os.getpid()}"

if __name__ == "__main__":
    # Par d√©faut, utilise autant de processus que de c≈ìurs CPU
    with Pool() as pool:
        numbers = [1, 2, 3, 4, 5, 6, 7, 8]
        
        # Distribue le travail et rassemble les r√©sultats (comme le map() classique)
        results = pool.map(square, numbers)

    for res in results:
        print(res)
```

---

## 4. Communication Inter-Processus (IPC) {#communication-inter-processus}

### 1. Quoi
Comme la m√©moire n'est pas partag√©e, on ne peut pas utiliser une variable globale pour communiquer. Il faut utiliser des canaux explicites comme `Queue` ou `Pipe`.

### 2. Pourquoi
Pour √©changer des donn√©es entre le processus parent et les enfants, ou entre enfants.

### 3. Comment

#### A. Utilisation de `Queue`
Attention : Ce n'est pas `queue.Queue` (threads), mais `multiprocessing.Queue`.

```python
from multiprocessing import Process, Queue

def producer(q):
    q.put("Donn√©e importante")
    print("üì§ Producteur a envoy√© la donn√©e")

def consumer(q):
    data = q.get() # Bloquant jusqu'√† r√©ception
    print(f"üì• Consommateur a re√ßu : {data}")

if __name__ == "__main__":
    q = Queue()
    
    p1 = Process(target=producer, args=(q,))
    p2 = Process(target=consumer, args=(q,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
```

### üö® Limitations de IPC
Transf√©rer des objets entre processus implique de les **s√©rialiser** (pickle) et de les d√©s√©rialiser. Si vous transf√©rez des gigaoctets de donn√©es, le co√ªt de copie peut annuler le gain de performance du parall√©lisme.

---

## Questions cl√©s (validation des acquis du chapitre) {#questions-cles-43}

1.  **Pourquoi `multiprocessing` est-il n√©cessaire pour les calculs intensifs en Python ?**
    Car il contourne le GIL en cr√©ant des processus distincts, permettant l'utilisation r√©elle de plusieurs c≈ìurs CPU simultan√©ment.

2.  **Pourquoi doit-on prot√©ger le code principal avec `if __name__ == "__main__":` ?**
    Pour √©viter que chaque nouveau processus ne relance r√©cursivement la cr√©ation de nouveaux processus lors de l'importation du script (particuli√®rement sur Windows/macOS).

3.  **Quelle est la diff√©rence majeure concernant la m√©moire entre `threading` et `multiprocessing` ?**
    Les threads partagent la m√©moire. Les processus ont chacun leur propre m√©moire isol√©e.

4.  **Est-il plus rapide de lancer 100 processus pour 100 petites t√¢ches ?**
    Non. Le co√ªt de cr√©ation d'un processus est √©lev√© (overhead). Mieux vaut utiliser un `Pool` (ex: 4 workers) pour traiter les 100 t√¢ches.

---

## Exercices : {#exercices-43}

### Exercice 1 - La Course aux Nombres Premiers {#exercice-1-nombres-premiers}

üéØ **Objectif** : Comparer la performance S√©quentielle vs Multiprocessing.

üíº **Mise en situation** : Vous devez trouver le nombre de nombres premiers dans une large plage. C'est du pur calcul CPU.

üìù **√ânonc√©** :
1.  Cr√©ez une fonction `is_prime(n)` (algorithme na√Øf ok).
2.  Cr√©ez une fonction `count_primes(numbers)` qui compte les premiers dans une liste.
3.  G√©n√©rez une liste de 100 000 nombres al√©atoires.
4.  Mesurez le temps pour traiter tout en s√©quentiel.
5.  Mesurez le temps en divisant la liste en 4 morceaux et en utilisant 4 processus (`Pool`).

üì∫ **R√©sultat attendu** :
```text
S√©quentiel : ~4.2 secondes
Parall√®le (4 c≈ìurs) : ~1.3 secondes (Gain significatif !)
```

<details>
<summary>üí° Voir le code complet comment√©</summary>

```python
import time
from multiprocessing import Pool

def is_prime(n):
    if n < 2: return False
    if n == 2: return True
    if n % 2 == 0: return False
    for i in range(3, int(n**0.5) + 1, 2):
        if n % i == 0:
            return False
    return True

def count_primes_in_chunk(chunk):
    return sum(1 for n in chunk if is_prime(n))

if __name__ == "__main__":
    # G√©n√©ration des donn√©es
    data = list(range(100_000, 300_000))
    
    # --- S√âQUENTIEL ---
    start = time.perf_counter()
    res_seq = count_primes_in_chunk(data)
    end = time.perf_counter()
    print(f"S√©quentiel : {end - start:.2f}s (Trouv√©: {res_seq})")

    # --- PARALL√àLE ---
    start = time.perf_counter()
    # On d√©coupe en 4 parts
    chunk_size = len(data) // 4
    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]
    
    with Pool(processes=4) as pool:
        results = pool.map(count_primes_in_chunk, chunks)
        total = sum(results)
        
    end = time.perf_counter()
    print(f"Parall√®le : {end - start:.2f}s (Trouv√©: {total})")
```
</details>

### Exercice 2 - Traitement d'Images en Masse {#exercice-2-traitement-images}

üéØ **Objectif** : Utiliser `Pool` pour une t√¢che r√©aliste.

üíº **Mise en situation** : Une startup de e-commerce vous demande de redimensionner ("thumbnail") des milliers d'images produit t√©l√©charg√©es.

üìù **√ânonc√©** :
1.  Simulez une fonction `process_image(img_name)` qui dort 0.5s (simulation traitement lourd) et renvoie `f"{img_name}_thumb.jpg"`.
2.  Liste de 10 noms d'images.
3.  Utilisez `Pool().imap_unordered` pour traiter les images et afficher le r√©sultat d√®s qu'une image est pr√™te (pas besoin d'attendre la fin de tout le lot).

üì∫ **R√©sultat attendu** :
```text
Image 1 trait√©e...
Image 2 trait√©e...
(Les r√©sultats apparaissent par paquets de N c≈ìurs)
```

<details>
<summary>üí° Voir le code complet comment√©</summary>

```python
import time
import os
from multiprocessing import Pool

def process_image(img_name):
    # Simulation d'un traitement lourd (resize, filter...)
    time.sleep(0.5)
    return f"{img_name} -> {img_name}_thumb.jpg (PID: {os.getpid()})"

if __name__ == "__main__":
    images = [f"img_{i}.jpg" for i in range(10)]
    
    print("D√©but du traitement...")
    
    with Pool() as pool:
        # imap_unordered est id√©al pour afficher la progression en temps r√©el
        # Il retourne un it√©rateur
        for result in pool.imap_unordered(process_image, images):
            print(f"‚úÖ {result}")
            
    print("Traitement termin√©.")
```
</details>

### Exercice 3 - Variables Partag√©es (M√©moire Partag√©e) {#exercice-3-memoire-partagee}

üéØ **Objectif** : Manipuler des donn√©es communes entre processus (Avanc√©).

üíº **Mise en situation** : Plusieurs processus doivent mettre √† jour un compteur global atomique.

üìù **√ânonc√©** :
1.  Utilisez `multiprocessing.Value` pour cr√©er un entier partag√© initialis√© √† 0.
2.  Cr√©ez une fonction `increment(counter)` qui ajoute 100 au compteur.
3.  Lancez 10 processus qui ex√©cutent tous cette fonction.
4.  Affichez la valeur finale. Notez l'utilisation n√©cessaire d'un verrou (lock) qui est souvent inclus ou g√©r√© manuellement.

üì∫ **R√©sultat attendu** :
```text
Valeur finale attendue : 1000
```

<details>
<summary>üí° Voir le code complet comment√©</summary>

```python
from multiprocessing import Process, Value, Lock

def increment(counter, lock):
    for _ in range(100):
        with lock:
            counter.value += 1

if __name__ == "__main__":
    # 'i' pour integer, 0 valeur initiale
    shared_counter = Value('i', 0)
    lock = Lock()
    
    processes = []
    for _ in range(10):
        p = Process(target=increment, args=(shared_counter, lock))
        processes.append(p)
        p.start()
        
    for p in processes:
        p.join()
        
    print(f"Valeur finale du compteur partag√© : {shared_counter.value}")
```
</details>