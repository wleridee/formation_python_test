---
sidebar_label: Concurrence : Threads (threading)
sidebar_position: 42
---

# Chapitre 42 : Concurrence : Threads (threading)

Introduction aux threads, CrÃ©ation de threads, Verrous (locks), ProblÃ¨mes de concurrence

Dans un programme classique, les instructions s'exÃ©cutent les unes aprÃ¨s les autres. Si l'une d'elles prend du temps (tÃ©lÃ©charger un fichier, attendre une rÃ©ponse API), tout le programme se fige.
Le **multithreading** permet de lancer plusieurs tÃ¢ches en "parallÃ¨le" au sein du mÃªme processus. C'est l'outil idÃ©al pour garder une application rÃ©active pendant qu'elle effectue des opÃ©rations d'EntrÃ©e/Sortie (I/O).

---

## 1. Concepts de Base et le Module `threading` {#concepts-de-base-threading}

### 1. Quoi
Un **Thread** (fil d'exÃ©cution) est la plus petite unitÃ© de traitement qu'un systÃ¨me d'exploitation peut planifier.
Le module `threading` de la bibliothÃ¨que standard permet de crÃ©er et gÃ©rer ces threads en Python.

### 2. Pourquoi
Pour exÃ©cuter des tÃ¢ches bloquantes (I/O Bound) en arriÃ¨re-plan sans geler le programme principal.
*Exemple :* Une interface graphique ne doit pas se figer pendant que l'application sauvegarde un fichier.

### 3. Comment

#### A. Syntaxe de base

```python
import threading
import time

def worker(name):
    print(f"ğŸ§µ Thread {name} dÃ©marre")
    time.sleep(2) # Simule une tÃ¢che longue (I/O)
    print(f"âœ… Thread {name} terminÃ©")

# CrÃ©ation des threads
t1 = threading.Thread(target=worker, args=("A",))
t2 = threading.Thread(target=worker, args=("B",))

# DÃ©marrage
t1.start()
t2.start()

print("ğŸš€ Programme principal continue...")

# Attendre la fin des threads (optionnel mais recommandÃ© ici)
t1.join()
t2.join()

print("ğŸ Tout est fini")
```

**Sortie typique :**
```text
ğŸ§µ Thread A dÃ©marre
ğŸ§µ Thread B dÃ©marre
ğŸš€ Programme principal continue...
(2 secondes de pause)
âœ… Thread A terminÃ©
âœ… Thread B terminÃ©
ğŸ Tout est fini
```

### ğŸš¨ Limitations : Le GIL (Global Interpreter Lock)
Python (CPython) possÃ¨de un verrou global (GIL) qui empÃªche deux threads Python d'exÃ©cuter du bytecode **simultanÃ©ment** sur le mÃªme cÅ“ur CPU.
*   **ConsÃ©quence** : Le multithreading en Python n'accÃ©lÃ¨re PAS les calculs purs (CPU Bound).
*   **Usage idÃ©al** : OpÃ©rations I/O (RÃ©seau, Disque, Base de donnÃ©es) oÃ¹ le CPU attend de toute faÃ§on.

---

## 2. La Course aux DonnÃ©es (Race Conditions) {#race-conditions}

### 1. Quoi
Une **Race Condition** survient quand plusieurs threads accÃ¨dent et modifient une ressource partagÃ©e (variable, fichier) en mÃªme temps, sans coordination. Le rÃ©sultat final dÃ©pend de l'ordre alÃ©atoire d'exÃ©cution.

### 2. Pourquoi
C'est la source de bugs les plus difficiles Ã  reproduire. Une opÃ©ration comme `compteur += 1` n'est pas atomique (elle se dÃ©compose en lecture, addition, Ã©criture). Si un thread est interrompu au milieu, les donnÃ©es sont corrompues.

### 3. Comment

#### A. Exemple de bug (Race Condition)

```python
import threading

compteur = 0

def incrementer():
    global compteur
    for _ in range(1000000):
        compteur += 1

t1 = threading.Thread(target=incrementer)
t2 = threading.Thread(target=incrementer)

t1.start()
t2.start()
t1.join()
t2.join()

# On attendrait 2 000 000, mais on aura souvent moins (ex: 1 458 921)
print(f"Valeur finale : {compteur}") 
```

---

## 3. Synchronisation avec les Verrous (Locks) {#synchronisation-locks}

### 1. Quoi
Un **Lock** (verrou) est un mÃ©canisme qui permet Ã  un seul thread d'accÃ©der Ã  une section de code critique Ã  la fois.
Si un thread A possÃ¨de le verrou, le thread B doit attendre que A le relÃ¢che pour continuer.

### 2. Pourquoi
Pour garantir l'intÃ©gritÃ© des donnÃ©es partagÃ©es en rendant les opÃ©rations atomiques.

### 3. Comment

#### A. Utilisation de `Lock` avec `with`

```python
import threading

compteur = 0
verrou = threading.Lock() # CrÃ©ation du verrou

def incrementer_safe():
    global compteur
    for _ in range(1000000):
        # Acquisition automatique du verrou
        with verrou:
            compteur += 1 
        # RelÃ¢chement automatique Ã  la fin du bloc with

t1 = threading.Thread(target=incrementer_safe)
t2 = threading.Thread(target=incrementer_safe)

t1.start()
t2.start()
t1.join()
t2.join()

print(f"Valeur finale sÃ©curisÃ©e : {compteur}") # Toujours 2 000 000
```

### 4. Zone de Danger
âŒ **Deadlock (Interblocage)** : Si le thread A attend le verrou B, et que le thread B attend le verrou A, le programme se fige pour l'Ã©ternitÃ©.
âœ… **Bonne pratique** : Utilisez toujours `with lock:` pour garantir que le verrou est relÃ¢chÃ© mÃªme en cas d'exception.

---

## 4. `ThreadPoolExecutor` : La gestion moderne {#threadpoolexecutor}

### 1. Quoi
Une abstraction de haut niveau fournie par le module `concurrent.futures`. Elle gÃ¨re automatiquement un pool (groupe) de threads rÃ©utilisables.

### 2. Pourquoi
Plus simple et plus sÃ»r que de gÃ©rer manuellement `start()` et `join()`. Permet de rÃ©cupÃ©rer facilement les valeurs de retour des fonctions exÃ©cutÃ©es dans les threads.

### 3. Comment

```python
from concurrent.futures import ThreadPoolExecutor
import time

def telecharger_page(url):
    time.sleep(1) # Simule latence rÃ©seau
    return f"Contenu de {url}"

urls = ["google.com", "python.org", "github.com"]

# CrÃ©ation d'un pool de 3 workers
with ThreadPoolExecutor(max_workers=3) as executor:
    # Mappe la fonction sur la liste d'URLs
    resultats = executor.map(telecharger_page, urls)

for res in resultats:
    print(res)
```

---

## Questions clÃ©s (validation des acquis du chapitre) {#questions-cles-42}

1.  **Pourquoi le multithreading n'accÃ©lÃ¨re-t-il pas un calcul mathÃ©matique intensif en Python ?**
    Ã€ cause du **GIL (Global Interpreter Lock)** qui empÃªche l'exÃ©cution simultanÃ©e de bytecode Python sur plusieurs cÅ“urs. Seul un thread Python tourne Ã  la fois.

2.  **Quand faut-il utiliser des threads en Python ?**
    Pour les tÃ¢ches **I/O Bound** : requÃªtes rÃ©seau, lecture/Ã©criture disque, attente utilisateur.

3.  **Quel est le risque principal lors du partage de variables entre threads ?**
    Les **Race Conditions** (accÃ¨s concurrent non protÃ©gÃ©) qui corrompent les donnÃ©es.

4.  **Comment Ã©viter un Deadlock ?**
    Toujours acquÃ©rir les verrous dans le mÃªme ordre, utiliser des timeouts, ou prÃ©fÃ©rer des architectures sans Ã©tat partagÃ© (comme les queues).

---

## Exercices : {#exercices-42}

### Exercice 1 - Le TÃ©lÃ©chargeur ParallÃ¨le {#exercice-1-telechargeur-parallele}

ğŸ¯ **Objectif** : Comparer l'exÃ©cution sÃ©quentielle vs multithreadÃ©e.

ğŸ’¼ **Mise en situation** : Vous devez vÃ©rifier le statut de 5 sites web. En sÃ©quentiel, c'est lent.

ğŸ“ **Ã‰noncÃ©** :
1.  CrÃ©ez une fonction `check_site(url)` qui simule une requÃªte avec `time.sleep(1)` et affiche "Checked [url]".
2.  Liste d'URLs : `["site1", "site2", "site3", "site4", "site5"]`.
3.  Mesurez le temps total pour traiter la liste de maniÃ¨re sÃ©quentielle (boucle `for`).
4.  Mesurez le temps total en utilisant `ThreadPoolExecutor` avec 5 workers.

ğŸ“º **RÃ©sultat attendu** :
```text
SÃ©quentiel : environ 5 secondes.
ParallÃ¨le : environ 1 seconde.
```

<details>
<summary>ğŸ’¡ Voir le code complet commentÃ©</summary>

```python
import time
from concurrent.futures import ThreadPoolExecutor

urls = [f"site{i}" for i in range(1, 6)]

def check_site(url):
    time.sleep(1) # Simulation I/O
    return f"Checked {url}"

# --- Version SÃ©quentielle ---
start = time.perf_counter()
for url in urls:
    check_site(url)
end = time.perf_counter()
print(f"SÃ©quentiel : {end - start:.2f} secondes")

# --- Version ThreadÃ©e ---
start = time.perf_counter()
with ThreadPoolExecutor(max_workers=5) as executor:
    executor.map(check_site, urls)
end = time.perf_counter()
print(f"ParallÃ¨le : {end - start:.2f} secondes")
```
</details>

### Exercice 2 - Le Compte Bancaire PartagÃ© (Lock) {#exercice-2-compte-bancaire-lock}

ğŸ¯ **Objectif** : ProtÃ©ger une ressource critique.

ğŸ’¼ **Mise en situation** : Un compte commun est utilisÃ© par deux personnes (threads) simultanÃ©ment. L'une dÃ©pose, l'autre retire.

ğŸ“ **Ã‰noncÃ©** :
1.  Classe `BankAccount` avec un solde `balance = 100`.
2.  MÃ©thode `modify(amount)` qui lit le solde, fait un `sleep(0.001)` (pour provoquer la race condition), modifie, et sauvegarde.
3.  Lancez 100 threads qui font `+10` et 100 threads qui font `-10`.
4.  Sans Lock : le solde final sera faux.
5.  Ajoutez un `threading.Lock` pour corriger.

ğŸ“º **RÃ©sultat attendu** :
```text
Sans Lock : Solde final alÃ©atoire (ex: 80, 120...)
Avec Lock : Solde final exactement 100.
```

<details>
<summary>ğŸ’¡ Voir le code complet commentÃ©</summary>

```python
import threading
import time

class BankAccount:
    def __init__(self):
        self.balance = 100
        self.lock = threading.Lock() # Le gardien

    def modify(self, amount):
        # Section Critique protÃ©gÃ©e
        with self.lock:
            local_copy = self.balance
            time.sleep(0.001) # Le piÃ¨ge Ã  race condition
            local_copy += amount
            self.balance = local_copy

account = BankAccount()
threads = []

# 100 dÃ©pÃ´ts et 100 retraits
for _ in range(100):
    t_add = threading.Thread(target=account.modify, args=(10,))
    t_sub = threading.Thread(target=account.modify, args=(-10,))
    threads.extend([t_add, t_sub])
    t_add.start()
    t_sub.start()

for t in threads:
    t.join()

print(f"Solde final : {account.balance}")
```
</details>

### Exercice 3 - Producteur / Consommateur avec Queue {#exercice-3-producteur-consommateur}

ğŸ¯ **Objectif** : Communication inter-thread sÃ»re.

ğŸ’¼ **Mise en situation** : Un thread gÃ©nÃ¨re des commandes (Producteur), un autre les traite (Consommateur). Ils ne doivent pas se marcher dessus.

ğŸ“ **Ã‰noncÃ©** :
1.  Utilisez `queue.Queue` (qui est thread-safe par dÃ©faut, pas besoin de Lock manuel).
2.  `producer` : Ajoute 5 entiers dans la queue avec un petit dÃ©lai.
3.  `consumer` : RÃ©cupÃ¨re les entiers avec `q.get()` et affiche "Traitement de X". S'arrÃªte quand il reÃ§oit `None` (signal de fin).
4.  Lancez les deux threads.

ğŸ“º **RÃ©sultat attendu** :
```text
Produit 1
ConsommÃ© 1
Produit 2
ConsommÃ© 2...
TerminÃ©.
```

<details>
<summary>ğŸ’¡ Voir le code complet commentÃ©</summary>

```python
import threading
import queue
import time

def producer(q):
    for i in range(5):
        time.sleep(0.5)
        print(f"ğŸ­ Production commande {i}")
        q.put(i)
    # Signal de fin (Sentinel value)
    q.put(None) 
    print("ğŸ­ Production terminÃ©e")

def consumer(q):
    while True:
        item = q.get() # Bloque si vide
        if item is None:
            break # On arrÃªte la boucle
        print(f"ğŸ›’ Traitement commande {item}")
        time.sleep(1) # Simulation traitement
    print("ğŸ›’ Consommateur fermÃ©")

ma_queue = queue.Queue()

t1 = threading.Thread(target=producer, args=(ma_queue,))
t2 = threading.Thread(target=consumer, args=(ma_queue,))

t1.start()
t2.start()

t1.join()
t2.join()
```
</details>